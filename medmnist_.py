# -*- coding: utf-8 -*-
"""MedMNIST .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18DjOHSztP2t-SkOJg01wSl-zxps_g3VM

# **Classification of medical images with convolutional networks**
"""

!pip install medmnist

"""## Εισαγωγή αναγκαίων βιβλιοθηκών και πακέτων

"""

from tqdm import tqdm

import torch
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
from torch.optim import lr_scheduler

import medmnist
from medmnist import INFO
from sklearn.metrics import f1_score, accuracy_score
import numpy as np
import time

print("Pytorch version:", torch.__version__)
print("GPU available:", torch.cuda.is_available())

"""## Transforms

"""

data_transforms = {
    'train': transforms.Compose([
        #Data Augmentation
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        #Data Normalization
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ]),
    'test': transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ]),
}

"""## Colon Pathology dataset



"""

path_info = INFO['pathmnist']
path_task = path_info['task']
path_channels = path_info['n_channels']
path_classes = len(path_info['label'])

print ("Dataset images have", path_channels, "channels. The type of problem is", path_task, "classification with ", path_classes, "classes.")

Path_DataClass = getattr(medmnist, path_info['python_class'])

#load and (download) data
path_train_dataset = Path_DataClass(split='train', transform=data_transforms['train'], download=True)
path_val_dataset = Path_DataClass(split='val', transform=data_transforms['test'], download=True)
path_test_dataset = Path_DataClass(split='test', transform=data_transforms['test'], download=True)

print("---------------------------------------------------------------------")
print("Info for the dataset:")
print(path_train_dataset.info.keys())
print("Dataset description:")
print(path_train_dataset.info['description'])
print("Labels interpretation:")
print(path_train_dataset.info['label'])

BATCH_SIZE = 128

# encapsulate data into dataloader form
path_train_loader = data.DataLoader(dataset=path_train_dataset, batch_size=BATCH_SIZE, shuffle=True)
path_val_loader = data.DataLoader(dataset=path_val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)
path_test_loader = data.DataLoader(dataset=path_val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)

print("Image sample of the Colon Pathology dataset:")
path_train_dataset.montage(length=4)

"""## Create model


"""

from torch.nn.modules.activation import ReLU
from torch.nn.modules.batchnorm import BatchNorm2d

class Net(nn.Module):
  def __init__(self, num_classes):
      super().__init__()

      self.layer1 = nn.Sequential(
          nn.Conv2d(3, 16, kernel_size=3, padding=1),
          nn.BatchNorm2d(16),
          nn.ReLU()
      )

      self.layer2 = nn.Sequential(
          nn.Conv2d(16, 32, kernel_size=3, padding=1),
          nn.BatchNorm2d(32),
          nn.ReLU()
      )

      self.layer3 = nn.Sequential(
          nn.Conv2d(32, 64, kernel_size=5, padding=2),
          nn.BatchNorm2d(64),
          nn.ReLU(),
          nn.MaxPool2d(2, 2)
      )

      self.layer4 = nn.Sequential(
          nn.Conv2d(64, 64, kernel_size=3, padding=1),
          nn.BatchNorm2d(64),
          nn.ReLU(),
          nn.MaxPool2d(2, 2)
      )

      self.layer5 = nn.Sequential(
          nn.Conv2d(64, 64, kernel_size=3, padding=1),
          nn.BatchNorm2d(64),
          nn.ReLU(),
          nn.MaxPool2d(2, 2)
      )

      self.fc = nn.Sequential(
          nn.Linear(576, 1024),
          nn.ReLU(),
          nn.Linear(1024, num_classes)
      )

  def forward(self, x):
     x = self.layer1(x)
     x = self.layer2(x)
     x = self.layer3(x)
     x = self.layer4(x)
     x = self.layer5(x)
     x = x.view(x.size(0), -1)
     x = self.fc(x)
     return x

"""# Define Optimizer and Loss"""

import torch.optim as optim

path_model = Net(num_classes = path_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(path_model.parameters(), lr=0.005, momentum=0.9)
scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)
epochs = 9

#CUDA activation
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

"""# Training Code

"""

def train_loop(model, loss_fn, optimizer, scheduler, num_epochs, dataloader, dataSet):
    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        running_loss = 0.0
        model.train()
        for inputs, targets in tqdm(dataloader):
            inputs = inputs.to(device)
            targets = targets.to(device)

            # zero the parameter gradients
            optimizer.zero_grad()

            # Backpropagation
            outputs = model(inputs)
            targets = targets.squeeze().long()
            loss = loss_fn(outputs, targets)
            loss.backward()
            optimizer.step()

            #statistics
            running_loss += loss.item()

        scheduler.step()
        epoch_loss = running_loss / len(dataloader)
        print(f'Training Loss: {epoch_loss:.4f}')

        if dataSet == 'PathMNIST':
          test_loop(model, loss_fn, 'Train', 'PathMNIST')
          test_loop(model, loss_fn, 'Validation', 'PathMNIST')
          print('\n')
        elif dataSet == 'BloodMNIST':
          test_loop(model, loss_fn, 'Train', 'BloodMNIST')
          test_loop(model, loss_fn, 'Validation', 'BloodMNIST')
          print('\n')

    if dataSet == 'PathMNIST':
      test_loop(model, loss_fn, 'Test', 'PathMNIST')
    elif dataSet == 'BloodMNIST':
      test_loop(model, loss_fn, 'Test', 'BloodMNIST')

    print('Finished Training!!')

"""# Test Code"""

def test_loop(model, loss_fn, split, dataSet):
    model.eval()

    if dataSet == 'PathMNIST':
      if split == 'Train':
        dataloader = path_train_loader
      elif split == 'Validation':
        dataloader = path_val_loader
      else:
        dataloader = path_test_loader
    elif dataSet == 'BloodMNIST':
      if split == 'Train':
        dataloader = blood_train_loader
      elif split == 'Validation':
        dataloader = blood_val_loader
      else:
        dataloader = blood_test_loader

    running_accuracy = 0.0

    with torch.no_grad():
      for inputs, targets in dataloader:
          inputs = inputs.to(device)
          targets = targets.to(device)

          outputs = model(inputs)
          targets = targets.squeeze().long()
          outputs = outputs.softmax(dim=1)
          targets = targets.float().resize_(len(targets), 1)

          outputs = outputs.cpu().numpy()
          targets = targets.cpu().numpy()

          #in every batch calculate accuracy and add it to a running accuracy variable
          running_accuracy += accuracy_score(targets, np.argmax(outputs, axis=1))

      #accuracy average
      accuracy = running_accuracy / len(dataloader)

    print(f'{split} Accuracy: {accuracy:.4f}')

path_model = path_model.to(device)
train_loop(path_model, criterion, optimizer, scheduler, epochs, path_train_loader, 'PathMNIST')

"""## Blood Cell Microscope dataset"""

data_flag = 'bloodmnist'
download = True

info = INFO[data_flag]
task = info['task']
print (task)
blood_channels = info['n_channels']
blood_classes = len(info['label'])

Blood_Dataclass = getattr(medmnist, info['python_class'])

# load the data
blood_train_dataset = Blood_Dataclass(split='train', transform=data_transforms['train'], download=download)
blood_val_dataset = Blood_Dataclass(split='val', transform=data_transforms['test'], download=download)
blood_test_dataset = Blood_Dataclass(split='test', transform=data_transforms['test'], download=download)
print(blood_test_dataset.info)

# encapsulate data into dataloader form
blood_train_loader = data.DataLoader(dataset=blood_train_dataset, batch_size=BATCH_SIZE, shuffle=True)
blood_val_loader = data.DataLoader(dataset=blood_val_dataset, batch_size=2*BATCH_SIZE, shuffle=False)
blood_test_loader = data.DataLoader(dataset=blood_test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)

print("Image sample of the Blood Cell Microscope dataset:")
blood_train_dataset.montage(length=4)

"""# Training with Transfer Learning in BloodMNIST Dataset"""

import copy

#copy of the model
modelB = copy.deepcopy(path_model.state_dict())

#adjust the fully connected layer to BloodMNIST dataset
modelB.fc = nn.Sequential(
            nn.Linear(576, 1024),
            nn.ReLU(),
            nn.Linear(1024, blood_classes)
          )

#load modelB to path_model
path_model.load_state_dict(modelB)
path_model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(path_model.parameters(), lr=0.005, momentum=0.9)
scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)
epochs = 9

#train the model to BloodMNIST dataset
train_loop(path_model, criterion, optimizer, scheduler, epochs, blood_train_loader, 'BloodMNIST')

"""# Training without Transfer Learning in BloodMNIST dataset

"""

blood_model = Net(num_classes = blood_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(blood_model.parameters(), lr=0.005, momentum=0.9)
scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)
epochs = 9

blood_model.to(device)
train_loop(blood_model, criterion, optimizer, scheduler, epochs, blood_train_loader, 'BloodMNIST')